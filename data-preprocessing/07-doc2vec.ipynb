{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document To Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 14:48:42,337 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d256,n5,w5,mc5,s0.001,t3>', 'datetime': '2023-11-05T14:48:42.337518', 'gensim': '4.2.0', 'python': '3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.49-linuxkit-pr-x86_64-with-debian-buster-sid', 'event': 'created'}\n",
      "2023-11-05 14:48:42,341 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 14:48:44,937 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-11-05 14:48:46,684 : INFO : PROGRESS: at example #10000, processed 517170 words (296128 words/s), 9568 word types, 7888 tags\n",
      "2023-11-05 14:48:46,936 : INFO : collected 9763 word types and 8345 unique tags from a corpus of 10495 examples and 543448 words\n",
      "2023-11-05 14:48:46,937 : INFO : Creating a fresh vocabulary\n",
      "2023-11-05 14:48:46,966 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 3879 unique words (39.73% of original 9763, drops 5884)', 'datetime': '2023-11-05T14:48:46.966826', 'gensim': '4.2.0', 'python': '3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.49-linuxkit-pr-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "2023-11-05 14:48:46,967 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 532713 word corpus (98.02% of original 543448, drops 10735)', 'datetime': '2023-11-05T14:48:46.967809', 'gensim': '4.2.0', 'python': '3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.49-linuxkit-pr-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "2023-11-05 14:48:47,015 : INFO : deleting the raw counts dictionary of 9763 items\n",
      "2023-11-05 14:48:47,016 : INFO : sample=0.001 downsamples 88 most-common words\n",
      "2023-11-05 14:48:47,017 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 389976.5261449715 word corpus (73.2%% of prior 532713)', 'datetime': '2023-11-05T14:48:47.017379', 'gensim': '4.2.0', 'python': '3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.49-linuxkit-pr-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "2023-11-05 14:48:47,091 : INFO : estimated required memory for 3879 words and 256 dimensions: 20097972 bytes\n",
      "2023-11-05 14:48:47,092 : INFO : resetting layer weights\n",
      "2023-11-05 14:48:47,110 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 3879 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-11-05T14:48:47.110280', 'gensim': '4.2.0', 'python': '3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.49-linuxkit-pr-x86_64-with-debian-buster-sid', 'event': 'train'}\n",
      "2023-11-05 14:48:50,360 : INFO : EPOCH 0 - PROGRESS: at 1.54% examples, 2336 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:48:51,399 : INFO : EPOCH 0 - PROGRESS: at 31.84% examples, 29269 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:48:52,406 : INFO : EPOCH 0 - PROGRESS: at 61.30% examples, 45891 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:48:53,431 : INFO : EPOCH 0 - PROGRESS: at 93.49% examples, 59458 words/s, in_qsize 4, out_qsize 0\n",
      "2023-11-05 14:48:53,560 : INFO : EPOCH 0: training on 543448 raw words (400756 effective words) took 6.4s, 62167 effective words/s\n",
      "2023-11-05 14:48:56,507 : INFO : EPOCH 1 - PROGRESS: at 1.54% examples, 2560 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:48:57,562 : INFO : EPOCH 1 - PROGRESS: at 29.84% examples, 29357 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:48:58,590 : INFO : EPOCH 1 - PROGRESS: at 59.08% examples, 46762 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:48:59,638 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 59362 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:48:59,811 : INFO : EPOCH 1: training on 543448 raw words (400049 effective words) took 6.2s, 64031 effective words/s\n",
      "2023-11-05 14:49:03,349 : INFO : EPOCH 2 - PROGRESS: at 1.54% examples, 2130 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:04,674 : INFO : EPOCH 2 - PROGRESS: at 23.93% examples, 19699 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:05,920 : INFO : EPOCH 2 - PROGRESS: at 44.54% examples, 28920 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:06,963 : INFO : EPOCH 2 - PROGRESS: at 64.42% examples, 36088 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:08,087 : INFO : EPOCH 2 - PROGRESS: at 81.59% examples, 40231 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:08,488 : INFO : EPOCH 2: training on 543448 raw words (400511 effective words) took 8.7s, 46177 effective words/s\n",
      "2023-11-05 14:49:11,477 : INFO : EPOCH 3 - PROGRESS: at 1.54% examples, 2517 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:12,553 : INFO : EPOCH 3 - PROGRESS: at 29.22% examples, 29128 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:13,611 : INFO : EPOCH 3 - PROGRESS: at 46.34% examples, 35997 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:14,706 : INFO : EPOCH 3 - PROGRESS: at 67.95% examples, 43990 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:15,764 : INFO : EPOCH 3 - PROGRESS: at 87.26% examples, 48739 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:16,067 : INFO : EPOCH 3: training on 543448 raw words (400711 effective words) took 7.6s, 52902 effective words/s\n",
      "2023-11-05 14:49:19,120 : INFO : EPOCH 4 - PROGRESS: at 1.54% examples, 2472 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:20,171 : INFO : EPOCH 4 - PROGRESS: at 29.88% examples, 28698 words/s, in_qsize 5, out_qsize 1\n",
      "2023-11-05 14:49:21,245 : INFO : EPOCH 4 - PROGRESS: at 59.08% examples, 45497 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:22,291 : INFO : EPOCH 4 - PROGRESS: at 89.39% examples, 58016 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:22,460 : INFO : EPOCH 4: training on 543448 raw words (400310 effective words) took 6.4s, 62646 effective words/s\n",
      "2023-11-05 14:49:25,218 : INFO : EPOCH 5 - PROGRESS: at 1.54% examples, 2728 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:26,263 : INFO : EPOCH 5 - PROGRESS: at 29.84% examples, 31019 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:27,315 : INFO : EPOCH 5 - PROGRESS: at 57.11% examples, 47117 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:28,343 : INFO : EPOCH 5 - PROGRESS: at 83.39% examples, 57855 words/s, in_qsize 6, out_qsize 1\n",
      "2023-11-05 14:49:28,691 : INFO : EPOCH 5: training on 543448 raw words (400814 effective words) took 6.2s, 64360 effective words/s\n",
      "2023-11-05 14:49:31,850 : INFO : EPOCH 6 - PROGRESS: at 1.54% examples, 2377 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:32,925 : INFO : EPOCH 6 - PROGRESS: at 29.22% examples, 27878 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:33,986 : INFO : EPOCH 6 - PROGRESS: at 57.11% examples, 43151 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:35,019 : INFO : EPOCH 6 - PROGRESS: at 81.59% examples, 52590 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:35,370 : INFO : EPOCH 6: training on 543448 raw words (400171 effective words) took 6.7s, 59941 effective words/s\n",
      "2023-11-05 14:49:38,235 : INFO : EPOCH 7 - PROGRESS: at 1.54% examples, 2626 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:39,279 : INFO : EPOCH 7 - PROGRESS: at 27.88% examples, 28214 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:40,295 : INFO : EPOCH 7 - PROGRESS: at 53.80% examples, 43449 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:41,379 : INFO : EPOCH 7 - PROGRESS: at 81.59% examples, 55464 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:41,754 : INFO : EPOCH 7: training on 543448 raw words (400746 effective words) took 6.4s, 62807 effective words/s\n",
      "2023-11-05 14:49:44,517 : INFO : EPOCH 8 - PROGRESS: at 1.54% examples, 2740 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:45,632 : INFO : EPOCH 8 - PROGRESS: at 29.84% examples, 30374 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:46,700 : INFO : EPOCH 8 - PROGRESS: at 59.08% examples, 47666 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:47,778 : INFO : EPOCH 8 - PROGRESS: at 87.26% examples, 58837 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:47,982 : INFO : EPOCH 8: training on 543448 raw words (400609 effective words) took 6.2s, 64357 effective words/s\n",
      "2023-11-05 14:49:50,768 : INFO : EPOCH 9 - PROGRESS: at 1.54% examples, 2703 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:51,795 : INFO : EPOCH 9 - PROGRESS: at 23.93% examples, 25184 words/s, in_qsize 5, out_qsize 0\n",
      "2023-11-05 14:49:52,806 : INFO : EPOCH 9 - PROGRESS: at 48.67% examples, 39754 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:53,908 : INFO : EPOCH 9 - PROGRESS: at 76.38% examples, 52591 words/s, in_qsize 6, out_qsize 0\n",
      "2023-11-05 14:49:54,473 : INFO : EPOCH 9: training on 543448 raw words (401308 effective words) took 6.5s, 61869 effective words/s\n",
      "2023-11-05 14:49:54,474 : INFO : Doc2Vec lifecycle event {'msg': 'training on 5434480 raw words (4005985 effective words) took 67.4s, 59469 effective words/s', 'datetime': '2023-11-05T14:49:54.474289', 'gensim': '4.2.0', 'python': '3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.49-linuxkit-pr-x86_64-with-debian-buster-sid', 'event': 'train'}\n",
      "2023-11-05 14:49:54,475 : INFO : Doc2Vec lifecycle event {'fname_or_handle': './model/d2v_1105.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-11-05T14:49:54.475597', 'gensim': '4.2.0', 'python': '3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.49-linuxkit-pr-x86_64-with-debian-buster-sid', 'event': 'saving'}\n",
      "2023-11-05 14:49:54,476 : INFO : not storing attribute cum_table\n",
      "2023-11-05 14:49:54,511 : INFO : saved ./model/d2v_1105.model\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "INPUT_FILE_PATH = \"./output/04_data_output.xlsx\" # 입력 파일 경로\n",
    "MODEL_OUPUT_PATH = \"./model/\" # 출력 폴더 경로\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) # 로깅 설정\n",
    "\n",
    "# Doc2Vec 모델에 입력될 형식을 클래스로 지정\n",
    "class Doc2VecInput:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "\n",
    "    def __iter__(self):\n",
    "        dataframe = pd.read_excel(self.filepath) # 입력 파일 읽기\n",
    "        for _, row in dataframe.iterrows():\n",
    "            tags = [row['court_name'] + \"/\" + row['case_number']] # 문서의 ID는 '법원명/판례번호'로 설정\n",
    "            tokens = row['extracted_nouns'].split() # extracted_nouns를 토큰으로 입력\n",
    "            yield TaggedDocument(words = tokens, tags = tags) # yield로 값을 계속 누적하여 반환\n",
    "\n",
    "# 모델 입력 정의\n",
    "document_input = Doc2VecInput(INPUT_FILE_PATH)\n",
    "\n",
    "# 모델 초기화 및 단어 구축, 학습 진행\n",
    "model = Doc2Vec(vector_size = 256, min_count = 5, epochs = 10)\n",
    "model.build_vocab(document_input)\n",
    "model.train(document_input, total_examples = model.corpus_count, epochs = model.epochs)\n",
    "\n",
    "# 결과 디렉토리가 없으면 생성\n",
    "if not os.path.exists(MODEL_OUPUT_PATH):\n",
    "    os.makedirs(MODEL_OUPUT_PATH)\n",
    "\n",
    "# 모델 저장\n",
    "model.save(os.path.join(MODEL_OUPUT_PATH, \"d2v_1105.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기 및 유사 판례 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 14:49:57,949 : INFO : loading Doc2Vec object from ./model/d2v_1105.model\n",
      "2023-11-05 14:49:57,974 : INFO : loading dv recursively from ./model/d2v_1105.model.dv.* with mmap=None\n",
      "2023-11-05 14:49:57,975 : INFO : loading wv recursively from ./model/d2v_1105.model.wv.* with mmap=None\n",
      "2023-11-05 14:49:57,976 : INFO : setting ignored attribute cum_table to None\n",
      "2023-11-05 14:49:58,064 : INFO : Doc2Vec lifecycle event {'fname': './model/d2v_1105.model', 'datetime': '2023-11-05T14:49:58.064740', 'gensim': '4.2.0', 'python': '3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.49-linuxkit-pr-x86_64-with-debian-buster-sid', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('의정부지방법원/2021고단360', 0.9436867237091064), ('의정부지방법원/2020고단7079', 0.9436052441596985), ('서울남부지방법원/2021고단1250', 0.943051815032959), ('의정부지방법원/2021고단717', 0.9414937496185303), ('서울동부지방법원/2021고단2483', 0.9405165910720825), ('의정부지방법원/2021고단2777', 0.9365559220314026), ('서울동부지방법원/2021고단2887', 0.9355080127716064), ('서울동부지방법원/2022고단1078', 0.9339799880981445), ('의정부지방법원/2021고단2533', 0.9333634376525879), ('서울남부지방법원/2022고단2516', 0.9331834316253662)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "\n",
    "MODEL_PATH = \"./model/d2v_1105.model\"\n",
    "\n",
    "inp_tokens = \"살인 강도\".split() # 입력 토큰 지정\n",
    "\n",
    "# 모델 불러오기 및 결과 도출\n",
    "model = Doc2Vec.load(MODEL_PATH)\n",
    "inp_vector = model.infer_vector(inp_tokens)\n",
    "print(model.docvecs.most_similar([inp_vector]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
