{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 징역 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "seed_value= 42\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 가져오기 및 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_excel(\"./output/02-extract-nouns.xlsx\", engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataframe['extracted_nouns'], dataframe['imprisonment'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토크나이저 정의 및 임베딩 행렬 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "sequence_length = 256\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_features, split=' ', oov_token='<unw>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, sequence_length)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, sequence_length)\n",
    "\n",
    "# 인퍼런스 환경에서 만들어진 토크나이저를 사용하기 위해 피클로 저장\n",
    "# import pickle\n",
    "\n",
    "# with open('./model/tokenizer.pickle', 'wb') as handle:\n",
    "#     pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12673\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(\"./model/ft_1119.txt\",  encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "num_words = min(max_features, len(word_index)) + 1\n",
    "print(num_words)\n",
    "embedding_dim = 200\n",
    "num_filters = 100\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.randn(embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_3 = tf.keras.Input(dtype = tf.float32, shape = (sequence_length,))\n",
    "embedding_layer_3 = tf.keras.layers.Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                            input_length=sequence_length,\n",
    "                            trainable=True)(input_3)\n",
    "\n",
    "reshape_3 = tf.keras.layers.Reshape((sequence_length, embedding_dim, 1))(embedding_layer_3)\n",
    "\n",
    "conv_0_3 = tf.keras.layers.Conv2D(num_filters, kernel_size=(3, embedding_dim), activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(3))(reshape_3)\n",
    "conv_1_3 = tf.keras.layers.Conv2D(num_filters, kernel_size=(4, embedding_dim), activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(3))(reshape_3)\n",
    "conv_2_3 = tf.keras.layers.Conv2D(num_filters, kernel_size=(5, embedding_dim), activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(3))(reshape_3)\n",
    "\n",
    "maxpool_0_3 = tf.keras.layers.MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1), padding='valid')(conv_0_3)\n",
    "maxpool_1_3 = tf.keras.layers.MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1), padding='valid')(conv_1_3)\n",
    "maxpool_2_3 = tf.keras.layers.MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1), padding='valid')(conv_2_3)\n",
    "\n",
    "concatenated_tensor_3 = tf.keras.layers.Concatenate(axis=1)([maxpool_0_3, maxpool_1_3, maxpool_2_3])\n",
    "flatten_3 = tf.keras.layers.Flatten()(concatenated_tensor_3)\n",
    "dropout_3 = tf.keras.layers.Dropout(rate = 0.5)(flatten_3)\n",
    "\n",
    "dense_layer_3 = tf.keras.layers.Dense(units = 256, activation = tf.nn.relu)(dropout_3)\n",
    "dense_layer_4 = tf.keras.layers.Dense(units = 64, activation = tf.nn.relu)(dense_layer_3)\n",
    "dense_layer_5 = tf.keras.layers.Dense(units = 16, activation = tf.nn.relu)(dense_layer_4)\n",
    "\n",
    "output = tf.keras.layers.Dense(units = 1, activation = tf.nn.relu)(dense_layer_5)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_3, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 256, 200)             2534600   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 256, 200, 1)          0         ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 254, 1, 100)          60100     ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 253, 1, 100)          80100     ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 252, 1, 100)          100100    ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 1, 1, 100)            0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 1, 1, 100)            0         ['conv2d_1[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 100)            0         ['conv2d_2[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 3, 1, 100)            0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'max_pooling2d_1[0][0]',     \n",
      "                                                                     'max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 300)                  0         ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 300)                  0         ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  77056     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 64)                   16448     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 16)                   1040      ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    17        ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2869461 (10.95 MB)\n",
      "Trainable params: 2869461 (10.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001), metrics=['mse', 'mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 65s 123ms/step - loss: 46.8578 - mse: 36.0800 - mae: 3.4342 - val_loss: 52.8253 - val_mse: 47.0981 - val_mae: 3.0944\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "history = model.fit(x=X_train, y=y_train, batch_size=32, epochs=50, verbose=1, validation_split=0.1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/imprisonment_231119.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 결과값이 회귀 형태로 도출되기 때문에 이를 분류 문제로 변경하기 위해 예측값과 실제값이 오차범위 내에 있다면 정답, 아니라면 오답이라 간주하여 정확도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 19ms/step\n",
      "0.8211100099108027\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "from keras.models import load_model\n",
    "\n",
    "def calculate_accuracy(model, inputs, labels, error_torlerance=0.2):\n",
    "    y_hats = model.predict(inputs)\n",
    "    score = sum([True if abs(y_hat - labels[i]) <= error_torlerance else False for i, y_hat in enumerate(y_hats)])\n",
    "    print(score / len(inputs))\n",
    "\n",
    "model = load_model(\"./model/imprisonment_231119.keras\")\n",
    "calculate_accuracy(model, X_test, y_test.to_numpy(), error_torlerance=5) # 예측과 정답 간 error_torlerance 차이는 정답이라 가정"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
