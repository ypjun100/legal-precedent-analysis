{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 15:16:03.794645: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 15:16:04.321898: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 15:16:04.415422: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 15:16:07.093092: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/envs/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection opened\n",
      "TurtleMQ ← {\"type\":\"REGISTER_WORKER\", \"data\":\"\"}\n",
      "TurtleMQ → {\"type\":\"REGISTER_WORKER\",\"messageId\":null,\"data\":\"\"}\n",
      "TurtleMQ → {\"type\":\"REQUEST_TASK\",\"messageId\":null,\"data\":\"전동킥보드 진로변경 금지 위반 중앙선 침범 도주치상 사문서위조 \",\"taskId\":\"b5f69a76-1344-4147-a780-a733c2e8d8cc\"}\n",
      "TurtleMQ ← {\"type\": \"RESPONSE_TASK\", \"taskId\": \"b5f69a76-1344-4147-a780-a733c2e8d8cc\", \"data\": \"{\\\"imprisonment\\\": 9, \\\"probation\\\": 24, \\\"fine\\\": 0, \\\"judgementDecision\\\": \\\"\\\\uc608\\\\uc0c1 \\\\ud310\\\\uacb0\\\\uc740 \\\\uc544\\\\uc9c1 \\\\uc9c0\\\\uc6d0\\\\ub418\\\\uc9c0 \\\\uc54a\\\\uc2b5\\\\ub2c8\\\\ub2e4.\\\", \\\"similarPrecedents\\\": [\\\"\\\\uc11c\\\\uc6b8\\\\ub0a8\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2020\\\\uace0\\\\ub2e84219 34\\\", \\\"\\\\uc11c\\\\uc6b8\\\\ub0a8\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2021\\\\uace0\\\\ub2e83240 34\\\", \\\"\\\\uc6b8\\\\uc0b0\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2021\\\\uace0\\\\ub2e82299 34\\\", \\\"\\\\uc11c\\\\uc6b8\\\\ub0a8\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2020\\\\uace0\\\\ub2e83829 33\\\", \\\"\\\\uc11c\\\\uc6b8\\\\ub0a8\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2020\\\\uace0\\\\ub2e84470 33\\\"]}\"}\n",
      "Connection closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Socket connection is closed.\n"
     ]
    }
   ],
   "source": [
    "import websocket\n",
    "import rel\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from gensim.models import Doc2Vec\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "TURTLEMQ_URL = \"ws://110.165.18.105/turtle/\"\n",
    "\n",
    "# Interval\n",
    "STOPWORDS_DICT_PATH = \"./user_dic/stopwords\"\n",
    "TOKENIZER_PATH = \"./model/tokenizer.pickle\"\n",
    "\n",
    "# MLP\n",
    "IMPRISONMENT_MLP_MODEL_PATH = \"./model/imprisonment_231119.keras\"\n",
    "PROBATION_MODEL_PATH = \"./model/probation_231120.keras\"\n",
    "FINE_MODEL_PATH = \"./model/fine_231121.keras\"\n",
    "\n",
    "# KOBERT\n",
    "IMPRISONMENT_KOBERT_MODEL_PATH = \"./model/kobert_imprisonment_231119_1.h5\"\n",
    "\n",
    "# DOC2VEC\n",
    "D2V_MODEL_PATH = \"./model/d2v_231117.model\"\n",
    "\n",
    "\n",
    "class Worker:\n",
    "    def __init__(self):\n",
    "        # 형태소 분석기\n",
    "        self.okt = Okt()\n",
    "\n",
    "        # 불용어 사전\n",
    "        self.stopwords = set()\n",
    "        with open(STOPWORDS_DICT_PATH, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                self.stopwords.add(line.strip())\n",
    "\n",
    "        # 토크나이저 불러오기\n",
    "        self.tokenizer = {}\n",
    "        with open(TOKENIZER_PATH, 'rb') as handle:\n",
    "            self.tokenizer = pickle.load(handle)\n",
    "\n",
    "        # MLP 모델 불러오기\n",
    "        self.imprisonment_mlp_model = load_model(IMPRISONMENT_MLP_MODEL_PATH)\n",
    "        self.probation_model = load_model(PROBATION_MODEL_PATH)\n",
    "        self.fine_model = load_model(FINE_MODEL_PATH)\n",
    "\n",
    "        # KoBERT 모델 불러오기\n",
    "        self.imprisonment_kobert_model = load_model(IMPRISONMENT_KOBERT_MODEL_PATH)\n",
    "        self.kobert_tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\")\n",
    "        self.kobert_model = AutoModel.from_pretrained(\"monologg/kobert\")\n",
    "        self.kobert_model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "        # Doc2Vec 모델\n",
    "        self.d2v_model = Doc2Vec.load(D2V_MODEL_PATH)\n",
    "\n",
    "\n",
    "    def on_open(self, ws):\n",
    "        print(\"Connection opened\")\n",
    "        self.send('{\"type\":\"REGISTER_WORKER\", \"data\":\"\"}') # 초기 패킷 (워커 등록)\n",
    "\n",
    "\n",
    "    def on_message(self, ws, message):\n",
    "        print(\"TurtleMQ →\", message)\n",
    "\n",
    "        message = json.loads(message)\n",
    "\n",
    "        if message['type'] == \"REQUEST_TASK\":\n",
    "            result = { \"imprisonment\": 0, \"probation\": 0, \"fine\": 0, \"judgementDecision\": \"예상 판결은 아직 지원되지 않습니다.\", \"similarPrecedents\": [] }\n",
    "\n",
    "            # 텍스트 클렌징 진행\n",
    "            clean_text = self.get_clean_text(message['data'].strip())\n",
    "\n",
    "            # 띄어쓰기 수정\n",
    "            clean_text = self.correct_spacing(clean_text)\n",
    "\n",
    "            # 명사 추출\n",
    "            extracted_nouns = self.extract_nouns(clean_text)\n",
    "\n",
    "            # 토크나이징\n",
    "            tokens = self.get_tokenized_sequences(extracted_nouns)\n",
    "\n",
    "\n",
    "            # 징역 예측 (MLP모델과 KoBERT 모델 결과의 평균)\n",
    "            result['imprisonment'] = int((self.predict_imprisonment_kobert(extracted_nouns) + self.predict_imprisonment_mlp(tokens)) / 2)\n",
    "\n",
    "            # 집행유예 예측\n",
    "            result['probation'] = int(self.predict_probation(tokens) * 100)\n",
    "\n",
    "            # 벌금 예측\n",
    "            result['fine'] = int(self.predict_fine(tokens)) * 10000\n",
    "            \n",
    "\n",
    "            # 유사 판례 계산\n",
    "            result['similarPrecedents'] = self.get_similar_precedents(extracted_nouns)\n",
    "\n",
    "            response = { \"type\": \"RESPONSE_TASK\", \"taskId\": message[\"taskId\"], \"data\": json.dumps(result) }\n",
    "            self.send(json.dumps(response))\n",
    "\n",
    "\n",
    "\n",
    "    def on_error(self, ws, error):\n",
    "        print(error)\n",
    "\n",
    "    def on_close(self, ws, close_status_code, close_msg):\n",
    "        self.on_exit()\n",
    "\n",
    "    def on_exit(self):\n",
    "        if self.ws.keep_running:\n",
    "            self.ws.close()\n",
    "\n",
    "        print(\"Connection closed\")\n",
    "        raise SystemExit(\"Socket connection is closed.\")\n",
    "\n",
    "    def run(self):\n",
    "        self.ws = websocket.WebSocketApp(TURTLEMQ_URL,\n",
    "                                on_open=self.on_open,\n",
    "                                on_message=self.on_message,\n",
    "                                on_error=self.on_error,\n",
    "                                on_close=self.on_close)\n",
    "        \n",
    "        get_ipython().events.register('post_execute', self.on_exit)\n",
    "\n",
    "        self.ws.run_forever(dispatcher=rel, reconnect=5)  # 연결 실패면 5초뒤 다시 연결 시도\n",
    "        rel.dispatch()\n",
    "\n",
    "\n",
    "    # 텍스트 클렌징\n",
    "    def get_clean_text(self, text) -> str:\n",
    "        text = text.replace(',','').replace('\"','').replace('\\'','').replace('.','').replace('(',' ').\\\n",
    "            replace(')','').replace('!','').replace('?','').replace(':','').replace(';','').lower()\n",
    "        text = text.replace(\"\\n\",\" \")\n",
    "        text = re.sub(r'\\d+?\\.\\s\\d+\\.\\s\\d+\\.', '', text) # 날짜 제거\n",
    "        text = re.sub(r'\\b\\w+법원|지원', '', text) # 법원명 제거\n",
    "        text = re.sub('수사보고|범 죄 사 실|범죄사실', '', text) # 판례의 기본적인 문구 제거\n",
    "        text = re.sub(r'[「」『』\\[\\],.:%○]', '', text) # 특수기호 제거\n",
    "        return text\n",
    "\n",
    "    # 띄어쓰기 고치기\n",
    "    def correct_spacing(self, text):\n",
    "        tagged = self.okt.pos(text)\n",
    "        corrected = \"\"\n",
    "        for i in tagged:\n",
    "            if i[1] in ('Josa', 'PreEomi', 'Eomi', 'Suffix', 'Punctuation'):\n",
    "                corrected += i[0]\n",
    "            else:\n",
    "                corrected += \" \"+i[0]\n",
    "        if corrected[0] == \" \":\n",
    "            corrected = corrected[1:]\n",
    "        return corrected\n",
    "\n",
    "    # 명사 추출\n",
    "    def extract_nouns(self, text):\n",
    "        nouns = []\n",
    "        for noun in self.okt.nouns(text):\n",
    "            if noun.isalpha() and (noun not in self.stopwords): # 단어에 숫자가 아닌 경우에만 저장 and 불용어 사전에 포함되지 않는 경우\n",
    "                nouns.append(noun)\n",
    "        return nouns\n",
    "\n",
    "    # 토크나이징\n",
    "    def get_tokenized_sequences(self, nouns):\n",
    "        out = self.tokenizer.texts_to_sequences([nouns])\n",
    "        return pad_sequences(out, 256)\n",
    "    \n",
    "    # 징역 예측 (MLP)\n",
    "    def predict_imprisonment_mlp(self, tokens):\n",
    "        return self.imprisonment_mlp_model.predict(tokens, verbose=0)\n",
    "    \n",
    "    # 징역 예측 (KoBERT)\n",
    "    def predict_imprisonment_kobert(self, nouns):\n",
    "        # 명사 병합\n",
    "        processed_text = ' '.join(nouns)\n",
    "\n",
    "        # 토큰화\n",
    "        tokenized_text = self.kobert_tokenizer.tokenize(processed_text)\n",
    "        tokenized_text = \" \".join([word for word in tokenized_text if word != '[UNK]'])\n",
    "        inputs = self.kobert_tokenizer(tokenized_text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(\"cuda\" if torch.cuda.is_available() else \"cpu\") for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.kobert_model(**inputs)\n",
    "\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).cpu().numpy()[0]\n",
    "        return self.imprisonment_kobert_model.predict(np.array([embedding]), verbose=0)[0][0]\n",
    "\n",
    "    # 집행유예 예측 (MLP)\n",
    "    def predict_probation(self, tokens):\n",
    "        return self.probation_model.predict(tokens, verbose=0)\n",
    "    \n",
    "    # 벌금 예측 (MLP)\n",
    "    def predict_fine(self, tokens):\n",
    "        return self.fine_model.predict(tokens, verbose=0)\n",
    "\n",
    "    # 유사 판례 계산\n",
    "    def get_similar_precedents(self, nouns):\n",
    "        result = []\n",
    "        input_data_vector = self.d2v_model.infer_vector(nouns)\n",
    "        for case in self.d2v_model.dv.most_similar([input_data_vector]):\n",
    "            # 결과 5개만 추출\n",
    "            if len(result) >= 5:\n",
    "                break\n",
    "            result.append('{} {}'.format(case[0], int(round(case[1], 2) * 100)))\n",
    "        return result\n",
    "        \n",
    "\n",
    "    def send(self, data):\n",
    "        if self.ws.keep_running:\n",
    "            self.ws.send(data)\n",
    "            print(\"TurtleMQ ←\", data)\n",
    "\n",
    "worker = Worker()\n",
    "worker.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
