{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 11:58:43.536509: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-17 11:58:43.644545: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-17 11:58:43.646495: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 11:58:44.936990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection opened\n",
      "TurtleMQ ← {\"type\":\"REGISTER_WORKER\", \"data\":\"\"}\n",
      "TurtleMQ → {\"type\":\"REGISTER_WORKER\",\"messageId\":null,\"data\":\"\"}\n",
      "TurtleMQ → {\"type\":\"REQUEST_TASK\",\"messageId\":null,\"data\":\"사고후미조치 도주치상 신호 또는 지시 위반 \",\"taskId\":\"867469cc-0f91-4584-b235-6d0150f54795\"}\n",
      "사고후미조치 도주치상 신호 또는 지시 위반\n",
      "['사고후미조치', '도주치상', '후미', '조치', '도주', '치상', '신호', '지시']\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "TurtleMQ ← {\"type\": \"RESPONSE_TASK\", \"taskId\": \"867469cc-0f91-4584-b235-6d0150f54795\", \"data\": \"{\\\"imprisonment\\\": 40, \\\"probation\\\": 0, \\\"fine\\\": 0, \\\"judgementDecision\\\": \\\"\\\\uc608\\\\uc0c1 \\\\ud310\\\\uacb0\\\\uc740 \\\\uc544\\\\uc9c1 \\\\uc9c0\\\\uc6d0\\\\ub418\\\\uc9c0 \\\\uc54a\\\\uc2b5\\\\ub2c8\\\\ub2e4.\\\", \\\"similarPrecedents\\\": [\\\"\\\\uc11c\\\\uc6b8\\\\uc11c\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2022\\\\uace0\\\\ub2e8869 36\\\", \\\"\\\\ucc3d\\\\uc6d0\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0\\\\uc9c4\\\\uc8fc\\\\uc9c0\\\\uc6d0/2021\\\\uace0\\\\ub2e81884 36\\\", \\\"\\\\uc758\\\\uc815\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2021\\\\uace0\\\\ub2e81494 35\\\", \\\"\\\\ucc3d\\\\uc6d0\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0\\\\uc9c4\\\\uc8fc\\\\uc9c0\\\\uc6d0/2020\\\\uace0\\\\ub2e81585 35\\\", \\\"\\\\uc11c\\\\uc6b8\\\\ub0a8\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2021\\\\uace0\\\\ub2e8415 35\\\"]}\"}\n",
      "TurtleMQ → {\"type\":\"REQUEST_TASK\",\"messageId\":null,\"data\":\"사고후미조치 도주치상 신호 또는 지시 위반\",\"taskId\":\"f398267d-953d-43e0-8d96-f1848aab4158\"}\n",
      "사고후미조치 도주치상 신호 또는 지시 위반\n",
      "['사고후미조치', '도주치상', '후미', '조치', '도주', '치상', '신호', '지시']\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "TurtleMQ ← {\"type\": \"RESPONSE_TASK\", \"taskId\": \"f398267d-953d-43e0-8d96-f1848aab4158\", \"data\": \"{\\\"imprisonment\\\": 40, \\\"probation\\\": 0, \\\"fine\\\": 0, \\\"judgementDecision\\\": \\\"\\\\uc608\\\\uc0c1 \\\\ud310\\\\uacb0\\\\uc740 \\\\uc544\\\\uc9c1 \\\\uc9c0\\\\uc6d0\\\\ub418\\\\uc9c0 \\\\uc54a\\\\uc2b5\\\\ub2c8\\\\ub2e4.\\\", \\\"similarPrecedents\\\": [\\\"\\\\uc11c\\\\uc6b8\\\\uc11c\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2022\\\\uace0\\\\ub2e8869 36\\\", \\\"\\\\uc758\\\\uc815\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2021\\\\uace0\\\\ub2e81494 35\\\", \\\"\\\\ucc3d\\\\uc6d0\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0\\\\uc9c4\\\\uc8fc\\\\uc9c0\\\\uc6d0/2021\\\\uace0\\\\ub2e81884 35\\\", \\\"\\\\uc758\\\\uc815\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0\\\\uace0\\\\uc591\\\\uc9c0\\\\uc6d0/2021\\\\uace0\\\\ub2e81494 35\\\", \\\"\\\\ucc3d\\\\uc6d0\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0\\\\uc9c4\\\\uc8fc\\\\uc9c0\\\\uc6d0/2020\\\\uace0\\\\ub2e81585 34\\\"]}\"}\n",
      "TurtleMQ → {\"type\":\"REQUEST_TASK\",\"messageId\":null,\"data\":\"사고후미조치\",\"taskId\":\"a729123c-6fc8-40fa-8f68-619f6f3410e8\"}\n",
      "사고후미조치\n",
      "['사고후미조치', '후미', '조치']\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "TurtleMQ ← {\"type\": \"RESPONSE_TASK\", \"taskId\": \"a729123c-6fc8-40fa-8f68-619f6f3410e8\", \"data\": \"{\\\"imprisonment\\\": 10, \\\"probation\\\": 0, \\\"fine\\\": 0, \\\"judgementDecision\\\": \\\"\\\\uc608\\\\uc0c1 \\\\ud310\\\\uacb0\\\\uc740 \\\\uc544\\\\uc9c1 \\\\uc9c0\\\\uc6d0\\\\ub418\\\\uc9c0 \\\\uc54a\\\\uc2b5\\\\ub2c8\\\\ub2e4.\\\", \\\"similarPrecedents\\\": [\\\"\\\\uc11c\\\\uc6b8\\\\ub0a8\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2021\\\\uace0\\\\ub2e81143 43\\\", \\\"\\\\uc6b8\\\\uc0b0\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2021\\\\uace0\\\\ub2e84134 41\\\", \\\"\\\\uc6b8\\\\uc0b0\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2021\\\\uace0\\\\ub2e83802 41\\\", \\\"\\\\uc11c\\\\uc6b8\\\\uc911\\\\uc559\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2022\\\\uace0\\\\ub2e8200 40\\\", \\\"\\\\uc11c\\\\uc6b8\\\\uc11c\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2020\\\\uace0\\\\ub2e82845 38\\\"]}\"}\n",
      "TurtleMQ → {\"type\":\"REQUEST_TASK\",\"messageId\":null,\"data\":\"혈중알코올농도 연쇄 추돌 \",\"taskId\":\"f559df68-505e-462f-b830-61679feb2496\"}\n",
      "혈중알코올농도 연쇄 추돌\n",
      "['혈중알코올농도', '혈중', '알코올', '농도', '연쇄', '추돌']\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "TurtleMQ ← {\"type\": \"RESPONSE_TASK\", \"taskId\": \"f559df68-505e-462f-b830-61679feb2496\", \"data\": \"{\\\"imprisonment\\\": 11, \\\"probation\\\": 0, \\\"fine\\\": 0, \\\"judgementDecision\\\": \\\"\\\\uc608\\\\uc0c1 \\\\ud310\\\\uacb0\\\\uc740 \\\\uc544\\\\uc9c1 \\\\uc9c0\\\\uc6d0\\\\ub418\\\\uc9c0 \\\\uc54a\\\\uc2b5\\\\ub2c8\\\\ub2e4.\\\", \\\"similarPrecedents\\\": [\\\"\\\\uc11c\\\\uc6b8\\\\ub0a8\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2021\\\\uace0\\\\uc815303 52\\\", \\\"\\\\uc11c\\\\uc6b8\\\\ub3d9\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2022\\\\uace0\\\\ub2e8387 49\\\", \\\"\\\\uc11c\\\\uc6b8\\\\ub0a8\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2021\\\\uace0\\\\ub2e82088 48\\\", \\\"\\\\uc11c\\\\uc6b8\\\\ubd81\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2020\\\\uace0\\\\uc8151277 48\\\", \\\"\\\\uc11c\\\\uc6b8\\\\ub3d9\\\\ubd80\\\\uc9c0\\\\ubc29\\\\ubc95\\\\uc6d0/2021\\\\uace0\\\\uc815700 48\\\"]}\"}\n"
     ]
    }
   ],
   "source": [
    "import websocket\n",
    "import rel\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from gensim.models import Doc2Vec, KeyedVectors\n",
    "from PyKomoran import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "TURTLEMQ_URL = \"ws://172.18.0.3:8080/turtle/\"\n",
    "KOMORAN_USER_DIC_PATH = \"./user_dic/dic1.user\"\n",
    "STOPWORDS_DICT_PATH = \"./user_dic/stopwords\"\n",
    "W2V_MODEL_PATH = \"./model/w2v_extracted_nouns_231117.txt\"\n",
    "DATA_PATH = \"./data/04_data_output.xlsx\"\n",
    "# DOC2VEC\n",
    "D2V_MODEL_PATH = \"./model/d2v_231117.model\"\n",
    "# Imprisonment\n",
    "IMPR_MODEL_PATH = \"./model/imprisonment_231117.h5\"\n",
    "\n",
    "class Worker:\n",
    "    def __init__(self):\n",
    "        # 학습 데이터 로드\n",
    "        data = pd.read_excel(DATA_PATH)\n",
    "\n",
    "        # 형태소 분석기(light, full)\n",
    "        self.komoran_light = Komoran(\"STABLE\")\n",
    "        self.komoran_full = Komoran(\"EXP\")\n",
    "        self.komoran_full.set_user_dic(KOMORAN_USER_DIC_PATH)\n",
    "\n",
    "        # 불용어 사전\n",
    "        self.stopwords = set()\n",
    "        with open(STOPWORDS_DICT_PATH, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                self.stopwords.add(line.strip())\n",
    "\n",
    "        # Word2Vec 임베딩 모델 로드\n",
    "        self.w2v_model = KeyedVectors.load_word2vec_format(W2V_MODEL_PATH, binary=False)\n",
    "\n",
    "        # 모든 텍스트 데이터를 Word2Vec 임베딩으로 변환하여 배열 생성\n",
    "        embeddings = []\n",
    "        for text in data['extracted_nouns']:\n",
    "            words = text.split()\n",
    "            word_vectors = [self.w2v_model[word] for word in words if word in self.w2v_model]\n",
    "            if len(word_vectors) > 0:\n",
    "                text_embedding = np.mean(word_vectors, axis=0)\n",
    "                embeddings.append(text_embedding)\n",
    "\n",
    "        # 표준화 스케일러 학습\n",
    "        self.scaler = StandardScaler().fit(embeddings)\n",
    "\n",
    "        # Imprisonment 모델 로드\n",
    "        self.impr_model = load_model(IMPR_MODEL_PATH)\n",
    "\n",
    "        # Doc2Vec 모델\n",
    "        self.d2v_model = Doc2Vec.load(D2V_MODEL_PATH)\n",
    "\n",
    "\n",
    "    def on_open(self, ws):\n",
    "        print(\"Connection opened\")\n",
    "        self.send('{\"type\":\"REGISTER_WORKER\", \"data\":\"\"}') # 초기 패킷 (워커 등록)\n",
    "\n",
    "\n",
    "    def on_message(self, ws, message):\n",
    "        print(\"TurtleMQ →\", message)\n",
    "\n",
    "        message = json.loads(message)\n",
    "\n",
    "        if message['type'] == \"REQUEST_TASK\":\n",
    "            result = { \"imprisonment\": 0, \"probation\": 0, \"fine\": 0, \"judgementDecision\": \"예상 판결은 아직 지원되지 않습니다.\", \"similarPrecedents\": [] }\n",
    "\n",
    "            # 텍스트 클렌징 진행\n",
    "            cleansing_text = self.get_cleansing_text(message['data'].strip())\n",
    "\n",
    "            # 명사 추출\n",
    "            extracted_nouns = self.get_nouns_from_text(cleansing_text)\n",
    "\n",
    "            # 징역 예측\n",
    "            result['imprisonment'] = int(self.predict_imprisonment(' '.join(extracted_nouns)))\n",
    "\n",
    "            # 유사 판례 계산\n",
    "            result['similarPrecedents'] = self.get_similar_precedents(extracted_nouns)\n",
    "\n",
    "            response = { \"type\": \"RESPONSE_TASK\", \"taskId\": message[\"taskId\"], \"data\": json.dumps(result) }\n",
    "            self.send(json.dumps(response))\n",
    "\n",
    "\n",
    "\n",
    "    def on_error(self, ws, error):\n",
    "        print(error)\n",
    "\n",
    "    def on_close(self, ws, close_status_code, close_msg):\n",
    "        self.on_exit()\n",
    "\n",
    "    def on_exit(self):\n",
    "        if self.ws.keep_running:\n",
    "            self.ws.close()\n",
    "\n",
    "        print(\"Connection closed\")\n",
    "        raise SystemExit(\"Socket connection is closed.\")\n",
    "\n",
    "    def run(self):\n",
    "        self.ws = websocket.WebSocketApp(TURTLEMQ_URL,\n",
    "                                on_open=self.on_open,\n",
    "                                on_message=self.on_message,\n",
    "                                on_error=self.on_error,\n",
    "                                on_close=self.on_close)\n",
    "        \n",
    "        get_ipython().events.register('post_execute', self.on_exit)\n",
    "\n",
    "        self.ws.run_forever(dispatcher=rel, reconnect=5)  # 연결 실패면 5초뒤 다시 연결 시도\n",
    "        rel.dispatch()\n",
    "\n",
    "\n",
    "    # 텍스트 클렌징\n",
    "    def get_cleansing_text(self, text) -> str:\n",
    "        text = re.sub(r'\\d+?\\.\\s\\d+\\.\\s\\d+\\.', '', text) # 날짜 제거\n",
    "        text = re.sub(r'\\b\\w+법원|지원', '', text) # 법원명 제거\n",
    "        text = re.sub('수사보고|범 죄 사 실|범죄사실', '', text) # 판례의 기본적인 문구 제거\n",
    "        text = re.sub(r'[「」『』\\[\\],.:%○]', '', text) # 특수기호 제거\n",
    "        return text\n",
    "    \n",
    "\n",
    "    # 명사 추출\n",
    "    def get_nouns_from_text(self, text) -> [str]:\n",
    "        # Full 명사 추출\n",
    "        nouns = []\n",
    "        for noun in self.komoran_full.get_nouns(text):\n",
    "            if noun.isalpha() and (noun not in self.stopwords) and (len(noun) > 1): # 단어에 숫자가 포함되지 않는 경우에만 저장 and 불용어 사전에 포함되지 않는 경우 and 단어 길이가 2이상인 단어만 저장\n",
    "                nouns.append(noun.replace(\" \", \"\")) # 띄어쓰기를 제거한 후 저장\n",
    "\n",
    "        # Light 명사 추출\n",
    "        for noun in self.komoran_light.get_nouns(text):\n",
    "            if noun.isalpha() and (noun not in self.stopwords) \\\n",
    "                and (len(noun) > 1):\n",
    "                nouns.append(noun.replace(\" \", \"\")) # 띄어쓰기 제거\n",
    "\n",
    "        return nouns\n",
    "\n",
    "    # 징역 예측\n",
    "    def predict_imprisonment(self, nouns_str):\n",
    "        # 텍스트를 Word2Vec 임베딩으로 변환\n",
    "        words = nouns_str.split()\n",
    "        word_vectors = [self.w2v_model[word] for word in words if word in self.w2v_model]\n",
    "\n",
    "        if len(word_vectors) > 0:\n",
    "            text_embedding = np.mean(word_vectors, axis=0).reshape(1, -1)\n",
    "            model_input = self.scaler.transform(text_embedding) # 스케일링 적용\n",
    "            prediction = self.impr_model.predict(model_input)\n",
    "            return prediction[0][0]\n",
    "        else: # 사전에 존재하지 않는 명사인 경우\n",
    "            return 0\n",
    "\n",
    "    # 유사 판례 계산\n",
    "    def get_similar_precedents(self, nouns: [str]) -> [str]:\n",
    "        result = []\n",
    "        input_data_vector = self.d2v_model.infer_vector(nouns)\n",
    "        for case in self.d2v_model.dv.most_similar([input_data_vector]):\n",
    "            # 결과 5개만 추출\n",
    "            if len(result) >= 5:\n",
    "                break\n",
    "            result.append('{} {}'.format(case[0], int(round(case[1], 2) * 100)))\n",
    "        return result\n",
    "        \n",
    "\n",
    "    def send(self, data):\n",
    "        if self.ws.keep_running:\n",
    "            self.ws.send(data)\n",
    "            print(\"TurtleMQ ←\", data)\n",
    "\n",
    "worker = Worker()\n",
    "worker.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
